
\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate, lineno]{lipics-v2021}
\usepackage[mode=buildnew]{standalone}% requires -shell-escape

\usepackage{minted}
\usepackage{macro}
\usepackage{xspace}
%\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory
\usepackage{tree}

\usetikzlibrary{positioning}


\bibliographystyle{plainurl}% the mandatory bibstyle
\title{Operational semantics for Prolog with Cut in Rocq and its application to determinacy analysis} %TODO Please add

%\titlerunning{Dummy short title} %TODO optional, please use if title is longer than one line

\author{Jane {Open Access}}{Dummy University Computing Laboratory, [optional: Address], Country \and My second affiliation, Country \and \url{http://www.myhomepage.edu} }{johnqpublic@dummyuni.org}{https://orcid.org/0000-0002-1825-0097}{(Optional) author-specific funding acknowledgements}%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional. Use additional curly braces to indicate the correct name splitting when the last name consists of multiple name parts.

\author{Joan R. Public\footnote{Optional footnote, e.g. to mark corresponding author}}{Department of Informatics, Dummy College, [optional: Address], Country}{joanrpublic@dummycollege.org}{[orcid]}{[funding]}

\authorrunning{J. Open Access and J.\,R. Public} %TODO mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'

\Copyright{Jane Open Access and Joan R. Public} %TODO mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 

\keywords{Dummy keyword} %TODO mandatory; please add comma-separated list of keywords

\category{} %optional, e.g. invited paper

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversiondetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93]{Classification (e.g. Full Version, Extended Version, Previous Version}{URL to related version} %linktext and cite are optional

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

\acknowledgements{I want to thank \dots}%optional

%\nolinenumbers %uncomment to disable line numbering



%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%TODO mandatory: add short abstract of the document
\begin{abstract}
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent convallis orci arcu, eu mollis dolor. Aliquam eleifend suscipit lacinia. Maecenas quam mi, porta ut lacinia sed, convallis ac dui. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse potenti. 
\end{abstract}

\section{Introduction}


Elpi is a dialect of \(\lambda\)Prolog (see \cite{1991miller-pf,Miller_Nadathur_2012,dunchev15lpar,TASSI_2019})
used as an extension language for the Rocq prover (formerly the Coq proof
assistant). Elpi has become an important infrastructure component: several
projects and libraries depend on it~\cite{krebbers25,Trakt,Trocq,Maas2024,fissore2023,fissore2024}.
Examples include the Hierarchy-Builder library-structuring tool~\cite{cohen_et_al:LIPIcs.FSCD.2020.34}
and Derive~\cite{tassi2018,tassi2019,tassi2023}, a program-and-proof synthesis
framework with industrial applications at SkyLabs AI.

Starting with version 3, Elpi gained a static analysis for
determinacy~\cite{10.1007/978-3-032-15981-6_5} to help users tame
backtracking. Rocq users are familiar with functional programming but
not necessarily with logic programming and uncontrolled backtracking
is a common source of inefficiency and makes debugging harder. The
determinacy checkers identifies predicates that behave like functions,
i.e., predicates that commit to their first solution and leave no
\emph{choice points} (places where backtracking could resume).

This paper reports our first steps towards a mechanization, in the Rocq
prover, of the determinacy analysis from~\cite{10.1007/978-3-032-15981-6_5}.
We focus on the control operator \emph{cut}, which is useful to restrict
backtracking but makes the semantic depart from a pure logical reading.

We formalize two operational semantics for Prolog with cut. The first is a
stack-based semantics that closely models Elpi's implementation and is
similar to the semantics mechanized by Pusch in Isabelle/HOL~\cite{10.1007/BFb0105415}
and to the model of Debray and Mishra~\cite[Sec.~4.3]{10.1016/0743-1066(88)90007-6}.
This stack-based semantics is a good starting point to study further
optimizations used by standard Prolog abstract machines~\cite{warren1983abstract,10.7551/mitpress/7160.001.0001},
but it makes reasoning about the scope of \emph{cut} difficult. To address
that limitation we introduce a tree-based semantics in which the branches
pruned by \emph{cut} are explicit and we prove the two semantics equivalent.
Using the tree-based semantics we then show that if every rule of a
predicate passes the determinacy analysis, the call to a deterministic
predicate does not leave any choice points.

\section{Common code: the language}
\begin{coqcode}
Inductive Tm := 
  | Tm_Kp    : Kp -> Tm
  | Tm_Kd    : Kd -> Tm
  | Tm_V     : V  -> Tm
  | Tm_Comb  : Tm -> Tm -> Tm.

Inductive Callable := 
  | Callable_Kp   : Kp -> Callable
  | Callable_V    : V -> Callable
  | Callable_Comb : Callable -> Tm -> Callable.

Inductive RCallable := 
  | RCallable_Kp   : Kp -> RCallable
  | RCallable_Comb : RCallable -> Tm -> RCallable.
\end{coqcode}

A callable term is a term without a data constructor as functor.

An rcallable is a term with rigid head.

\begin{coqcode}
Inductive A := cut | call : Callable -> A.
\end{coqcode}

An atom is the smallest syntactic unit that can be executed in a prolog
program \program. 
% The execution of an atom, inside a program and a substitution
% either succeeds returining an output substitution, or it fails.
% In both cases it returns a list of choice points, representing suspending
% states that can be resumed for backtracking.

\begin{coqcode}
Record R := mkR { head : RCallable; premises : list A }.
\end{coqcode}

We exploit the typing system to ensure that the head of a "valid" rule
is a term with rigid head.

\begin{coqcode}
(*simpler than in the code: signatures of preds are hidden*)
Definition program := seq R. 
\end{coqcode}

A program is made by a list of rules. Rules in \program are indexed by their
position in the list. Given a list of rules \rules and two indexes $i$ and $j$,
s.t. $i\neq j$ then, $\rules_i$\ has a higher priority then $\rules_j$.

\begin{figure}[!h]
\inputminted[fontsize=\small,autogobble,escapeinside=~~,mathescape=true,frame=leftline,framerule=0pt,framesep=1em]{elpi}{./prog.elpi}
\caption{Small program example}
\label{fig:prog}
\end{figure}

The elpi program above would be translated as a list of $6$ elements where the
heads and body are translated in the natural way.


Sigma is a substitution mapping variables to their term instantiation.
\begin{coqcode}
  Definition Sigma := {fmap V -> Tm}.
\end{coqcode}

The backchaining algorithm is the function \backchain aims to filter
only the rules in the program \program having rules unifying with the
current query $q$ in a given subtitution $\sigma$ using the list of modes $m$.
In particular \backchain returns for each selected rule $r$ a substitution
$\sigma'$ that is the substitution obtained by the unification of the query and
the head of $r$.

$$\backchain\ :\ (\program, \sigma, q) \to \texttt{seq}(\sigma * R)$$

\subsection{The cut operator}

The semantics of the cut operator we have chosen in the Elpi language is the
hard cut operator used in standard SWI-Prolog. It has two main roles: it
eliminates alternatives that are chonologically created both at the same moment
as, and after, the creation of the cut operator in the execution state. 

As a small example of this high-level definition. Let's take the program in
\cref{fig:prog} and the query $q =$~\elpiIn{g 2 Z}. All the $3$ rules for
\eI{g} can be used on the $q$. They are executed in order of the definition
in the progrma, i.e., r1 is tried first then r2 and finally r3.

The first rule has no premises returns the assignement \eI{Z = 2}.
We however are not finished, there are still two non-explored alternatives
consiting in the premises of $r2$ and $r3$.

The premises of $r2$ are ``\eI{r 2 Z, !}''. In this sequent the role of the cut
become evident: if it is executed, i.e. \eI{r 2 Z} succeeds, then the premises
of $r3$ will be cut away, since they have been created at the same time of the
creation of the cut in the alternatives list; moreover, if the call \eI{r 2 Z}
leaves alternatives, only the first is committed and the other are discarded,
since these alternatives would have a depper depth then the cut itself.

Concretely speaking, \eI{r 2 Z} will provide two alternatives, assigning
\eI{Z} respectively to \eI{4} and \eI{8}. The second solution is discaded by the
cut.


\section{Semantics intro}

We propose two operational semantics for a logic program with cut. The two
semantics are based on different syntaxes, the first syntax (called tree)
exploits a tree-like structure and is ideal both to have a graphical view of its
evolution while the state is being intepreted and to prove lemmas over it. The
second syntax, called elpi, is the elpi's syntax and has the advantage of
reducing the computational cost of cutting and backtracking alternatives by
using shared pointers. We aim to prove the equivalence of the two semantics
together with some interesting lemmas of the cut behavior.


\subsection{Tree semantics}
\input{tex_code/tree_def.tex}

In the tree we distinguish 6 main cases: \koC, \okC, and \deadC are special
meta-symbols representing, respectively, a failed, a successful, and a dead
terminal. These symbols are considered meta because they are internal
intermediate symbols used to give structure to the tree. While the first two
symbols are of immiediate understanding, we use \deadC to represent ghost state,
that is, the \deadC symbol is always ignored by the tree interpreter.

\taC (acronym for tree-atom) is the constructor of atoms in the tree.

The two recursive cases of a tree are the \orC and \andC non-terminals. The \orC
non-terminal \(A \lor B_\sigma\) denotes a disjunction between two trees \(A\) and
\(B\). The second branch is annotated with a suspended substitution \(\sigma\) so
that, upon backtracking to \(B\), \(\sigma\) is used as the initial substitution
for the execution of \(B\).

The \andC non-terminal \(A \land_{B_0} B\) represents a conjunction of two trees \(A\)
and \(B\). We call \(B_0\) the reset point for \(B\); it is used to restore the state
of \(B\) to its initial form if a backtracking operation occurs on \(A\). Intuitively
in prolog-like syntax, in a tree \(A \land_{B_0} B\), if \ttl is the function
flattening the tree in a list of sequents disjnction and $\ttl (A) = A_1,\dots, A_n$, 
then we would have $(A_1, \ttl\ B); (A_2, B0); \dots; (A_n, B0)$.

A graphical representation of the tree is shown in \cref{tree-ex1}. To make the
graph more compact, the \andC and \orC non-terminals are n-ary rather than binary,
with right-binding priority. The \koC and \deadC terminals act as the neutral elements
in the \orC list, while \okC is the neutral element of the \andC list.


% \begin{figure}
%   \input{tex_code/step_tag.tex}
%   \input{tex_code/step.tex}
% \caption{Step for tree semantics}
% \end{figure}

% \begin{figure}
%   \input{tex_code/next_alt.tex}
% \caption{backtracking operation}
% \end{figure}

The interpretation of a tree is performed by two main routines: \step and \na
that traverse the tree depth-first, left-to-right. Then, then \run inductive
makes the transitive closure of step \step and \na: it iterates the calls to its
auxiliary functions. In \cref{eq:stepT,eq:naT,eq:runT} we give the types
contrats of these symbols where \cI{fv} is a set of variable names.

\vspace{5pt}
\codeline[eq:steptag]{tex_code/step_tag.tex}
\codeline[eq:stepT]{tex_code/step_sig.tex}
\codeline[eq:naT]{tex_code/next_alt.tex}
\codeline[eq:runT]{tex_code/run_sig.tex}

\vspace{5pt}
A particular tree we want to identify is a \isdead tree (defined in \cref{fig:dead}). This tree has the
property to never produce a solution: it is eiher the \deadC tree
or both branches of \orC are dead, or the lhs of \andC is dead. In the 
latter case, we note that $B$ can be non-dead, but this is not a problem
since the interpreter can run $B$ only if $A$ is non-dead.

\begin{figure}
  \begin{subfigure}{0.45\textwidth}
  \input{tex_code/is_dead.tex}
  \caption{Defintion of \isdead}
  \label{fig:dead}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
  \input{tex_code/path_end.tex}
  \caption{Defintion of \pathend}
  \label{fig:pathend}
  \end{subfigure}
\end{figure}

The prolog interpreter explores the state in DFS strategy, it finds
the ``first-to-be-explored'' (ftbe) atom of the tree and then interpretes it.
In a non-\isdead tree, we get the ftbe node via \pathend,
shown in \cref{fig:pathend}.
The \pathend is either the tree itself if the tree is a leaf.
Otherwise, if the tree is a disjunction, the path continues on
the left- or the right-subtree depending of if the the lhs is
a \isdead tree. In the \orC case we are clearing ignoring the dead (ghost) state.

In the case of a conjunction, it is more interesting to see what happens.
If the \pathend $p$ of the lhs is a success then we look for 
the \pathend in the rhs, otherwise we return $p$.
In \cref{tree-ex1} the \pathend of the tree is \eI{g X}.
\begin{figure}
  \begin{subfigure}{0.25\textwidth}
    \begin{center}\includestandalone[width=0.8\textwidth]{./src/path}\end{center}
    \caption{Path end := g X Y}
    \label{tree-ex1} 
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includestandalone[width=\textwidth]{./src/path_exp}
    \caption{Step on g X Y using \cref{fig:prog}}
    \label{tree-ex1-exp} 
  \end{subfigure}
  \begin{subfigure}{0.3\textwidth}
    \includestandalone[width=1\textwidth]{./src/tree_cut}
    \caption{Scope of the cut}
    \label{cut-scope} 
  \end{subfigure}
\caption{Some tree representations} 
\end{figure}


Below we define two special kind of trees depending on their pathend.

\defline[def:success]{tex_code/succ_path.tex}
\defline[def:failed]{tex_code/failed_path.tex}

The \step procedure takes a program a substitution and a tree and returns a
\steptag together with a new tree. The \steptag is a tag telling what
kind of internal tree step has been performed. \cI{CutBrothers} stands
for the interpretation of a superficial cut, i.e. a cut having only
\andC-nodes as fathers; \cI{Expanded} stands for interpretation of non-superficial
or predicate calls; \cI{Failure} and \cI{Success} are returned for respectively
\success and \failed trees. 

\begin{lemma}[success\_step]
  $\forall p\ s\ T, \success\ T \to \step\ p\ s\ T = (\cI{Success}, T)$
\end{lemma}

\begin{lemma}[failed\_step]
  $\forall p\ s\ T, \failed\ T \to \step\ p\ s\ T = (\cI{Failure}, T)$
\end{lemma}


The step procedure is intended to interpretate atoms,
that is, it returnes the identity for tree 
Therefore, the two interesting cases of a tree step are the step of a call
and the step of a cut.

\textit{Call step} In the former case the call node is
replace with a new subtree made by the rules returned by the \backchain
function. If \backchain returns a list $l$,
if $l$ is empty then KO tree is returned, otherwise
the call is replaced by right-skewed tree made of $n$ inner Or nodes,
where $n$ is the length of $l$.
The root Or-node has KO as left child. The lhs of the other nodes is a
right-skewed tree of And nodes. The And nodes are again a right-seked tree
containing then atoms (either cut or call) \marginpar{dire dei reset point}
taken from the list $l$.

A step in the tree of \cref{tree-ex1} makes a backchain operation over the query
\eI{g X Y} and, in the program defined in \cref{fig:prog}, the new tree would be the one in
\cref{tree-ex1-exp}. We have put a red border aroung the new generated subtree.
It is a disjunction of four subtrees:
the first node is the KO node (by default), the second is OK, since r1
has no premises, the third and the fourth contains the premises of respectively
r2 and r3. \marginpar{dire che le sostituzioni del backchain sono importanti e dove sono mess}

\textit{Cut step} The latter case is delicate since interpreting a cut in a tree
has three main impacts: at first the cut node is replaced by a OK node, but then
we need to cut-away the subtrees that are in the scope of the cut: in particular
we need to soft-kill the left-siblings of the Cut and hard-kill the right-uncles
of the the Cut.

\begin{definition}[Left-siblings (resp. right-sibling)]
  Given a node $A$, the left-siblings (resp. right-sibling) of $A$
  are the list of subtrees sharing the same parent of $A$ and that appear
  on its left (resp. right).
\end{definition}

\begin{definition}[Right-uncles]
  Given a node $A$, the right-uncles of $A$ are the list of right-sibling of the
  father of $A$.
\end{definition}

\begin{definition}[Soft-kill]
  Given a tree $t$, soft-kill replaces all the leaves of the tree with the node
  KO except for the leaves that are part of the path $p$ of $t$.
\end{definition}

\begin{definition}[Hard-kill]
  Given a tree $t$, hard-kill replaces all the leaves of the tree with the node
  KO
\end{definition}

An example of the impact of the cut is show in \cref{cut-scope}. The step
routine interprets the cut if it is at the end of the current path. In the
example we have tagged in red the arrow $!_l$ indicating which sub-trees is
soft-killed and $!_r$ indicated which is sub-trees are to be hard-killed.


\subsubsection{Execution example}

\subsubsection{Valid tree}
% \begin{figure}  
%   \input{tex_code/valid_tree.tex}
%   $$\texttt{B.bbOr}\ A \iff \exists\ r\ rs, A = \texttt{big\_or\_aux}\ r\ rs \lor A = \texttt{cutr}(\texttt{big\_or\_aux}\ r\ rs)$$
% \caption{Valid tree}
% \end{figure}
\subsection{Elpi semantics}

TODO: dire che la semantica ad albero è puù faicle per le prove

The Elpi interpreter is based on an operational semantics
close to the one picked by Pusch in \cite{10.1007/BFb0105415}, in turn
closely related to the one given by Debray and Mishra in
\cite[Section 4.3]{10.1016/0743-1066(88)90007-6}. Push mechanized
the semantics in Isabelle/HOL together with some optimizations that
are present in the Warren Abstract Machine~\cite{warren1983abstract,10.7551/mitpress/7160.001.0001}.

In these operational semantics we need to decorate the cut
atom with a list of alternative, morally a pointer to a sub-list
of the overall alternatives. An atom in the elpi semantcis is defined as follows:

\input{tex_code/elpi_def.tex}

We are completely loosing the tree structure. There are no clean reset
points. The backtracking operation is simpler: it is the tail function.
The cutr and cutl operations disappears: the alternatives are stored 
directly in the cutE terminal.

The elpi interpreter is as follows:
\begin{minted}{coq}
(*TODO: add system of rules*)
Inductive nur : Sigma -> goals ->  alts -> Sigma -> alts -> Type :=
  | StopE s a : nur s nilC a s a
  | CutE s s1 a ca r gl : nur s gl ca s1 r -> nur s ((cutE ca) ::: gl) a s1 r
  | CallE p s s1 a b bs gl r t : 
    F u p t s = [:: b & bs ] -> 
      nur b.1 (save_goals a gl (a2gs1 p b)) (save_alts a gl ((aa2gs p) bs) ++ a) s1 r -> 
        nur s ((callE p t) ::: gl) a s1 r
  | FailE p s s1 s2 t gl a al r : 
    F u p t s = [::] -> nur s1 a al s2 r -> nur s ((callE p t) ::: gl) ((s1, a) ::: al) s2 r.
\end{minted}


The translation of a tree to a list is as follows:

\input{tex_code/t2l.tex}

\newcommand{\thte}{\texttt{tree\_to\_elpi}} % theorem tree to elpi name
\newcommand{\thet}{\texttt{elpi\_to\_tree}} % theorem elpi to tree name

\begin{theorem}[\thte]
\begin{align*}
  \forall A\ \sigma_1\ B\ \sigma_2\ b\ \sigma_0,
  \vt\ A \to \\
  \run_u\ \sigma_1\ A\ (Some\ \sigma_2)\ B\ b \to \\
    \exists x\ xs, 
      \ttl\ A\ \sigma_1\ \nilC = x ::: xs \land
      \nur_u\ x.1\ x.2\ xs\ \sigma_2\ (\ttl\ B\ \sigma_0\ \nilC).
\end{align*}

\end{theorem}

\begin{theorem}[\thet]
  \label{thet}
\begin{align*}
  \forall \sigma_1\ \sigma_2\ a\ na\ g, \\
  \nur_u\ \sigma_1\ g\ a\ \sigma_2\ na \to  \\
  \forall \sigma_0\ t, \vt\ t \to (\ttl\ t\ \sigma_0\ \nilC) = ((\sigma_1,g) ::: a) \to \\
  \exists t'\ n, \run_u\ \sigma_0\ t\ (Some\ \sigma_2)\ t'\ n \land \ttl\ t'\ \sigma_0\ \nilC = na.
\end{align*}
\end{theorem}

The proof of \cref{thet} is based on the idea explained in~\cite[Section
3.3]{yves-equiv}. An ideal statement for this lemma would be: given a function
\texttt{l2t} transforming an elpi state to a tree, we would have have that the
the execution of an elpi state $e$ is the same as executing \run on the tree
resulting from $\texttt{l2t}(e)$. However, it is difficult to retrive the
strucutre of an elpi state and create a tree from it. This is because, in an
elpi state, we have no clear information about the scope of an atom inside the
list and, therefore, no evident clue about where this atom should be place in
the tree. 

Our theorem states that, starting from a valid state $t$
which translates to a list of alternatives $(\sigma_1, g) :: a$.
If we run in elpi the list of alternatives, then the execution of the tree $t$
returns the same result as the execution in elpi. The proof is performed
by induction on the derivations of the elpi execution. We have $4$
derivations.

We have $4$ case to analyse:

% \begin{enumerate}
%   \item StopE: We have an empty list of goals, and therefore a success.\\
%         By the definition of \vt, we know that $\ttl t = 
% \end{enumerate}



% This means that multiple different (and non-equivalent) trees
% can be produced from a given elpi state.
% For example the elpi state $[[f X]; [g X]]$ could be represented by
% the tree $((Dead \lor f X) \lor g X)$




\begin{figure}
  \begin{center}
    \includestandalone[width=.2\textwidth]{src/e2t_ind}
  \end{center}
\caption{Induction scheme for \cref{thet}}  
\end{figure}

\bibliography{bib}
\end{document}
